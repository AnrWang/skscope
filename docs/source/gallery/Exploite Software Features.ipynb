{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f5e5d54",
   "metadata": {},
   "source": [
    "\n",
    "Determine the optimal support size\n",
    "------------\n",
    "\n",
    "We would like to use logistic regression to show how to determine the optimal support size based on different information criteria."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8486656",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Logistic regression is an important model to solve classification problem, which is expressed specifically as:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& P(y=1 \\mid x)=\\frac{1}{1+\\exp \\left(-x^T \\beta\\right)}, \\\\\n",
    "& P(y=0 \\mid x)=\\frac{1}{1+\\exp \\left(x^T \\beta\\right)},\n",
    "\\end{aligned}\n",
    "$$\n",
    "where $\\beta$ is an unknown parameter vector that to be estimated. Since we expect only a few explanatory variables contributing to predicting $y$, we assume $\\beta$ is sparse vector with sparsity level $s$.\n",
    "\n",
    "With $n$ independent data of the explanatory variables $x$ and the response variable $y$, we can estimate $\\beta$ by minimizing the negative log-likelihood function under sparsity constraint:\n",
    "\n",
    "<a id='loss'></a>\n",
    "$$\n",
    "\\arg \\min _{\\beta \\in R^p} L(\\beta):=-\\frac{1}{n} \\sum_{i=1}^n\\left\\{y_i x_i^T \\beta-\\log \\left(1+\\exp \\left(x_i^T \\beta\\right)\\right)\\right\\}, \\text { s.t. }\\|\\beta\\|_0 \\leq s \\tag{1}\n",
    "$$ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c6ce97f7",
   "metadata": {},
   "source": [
    "### Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4020f0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from skscope import ScopeSolver\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec16df9f",
   "metadata": {},
   "source": [
    "### Set a seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b49ef6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2024)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e3318e9",
   "metadata": {},
   "source": [
    "### Generate the data\n",
    "\n",
    "Firstly, we define a data generator function to provide a way to generate suitable dataset for this task.\n",
    "\n",
    "The model:\n",
    "\n",
    "* $\\beta^*_i$ ~ U(1, 2), $\\forall i \\in supp(\\beta^*)$\n",
    "* $x = (x_1, \\cdots, x_p)^T$, $x_{i+1}=\\rho x_i+\\sqrt{1-\\rho^2}z_i$, where $x_1, z_i$ ~ N(0, 1)\n",
    "* $y\\in\\{0,1\\}$, $P(y=0)=\\frac{1}{1+\\exp^{x^T\\beta^*+c}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61c642e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_logistic_data(n, p, s, rho, random_state=None):\n",
    "    np.random.seed(random_state)\n",
    "    # beta\n",
    "    beta = np.zeros(p)\n",
    "    true_support_set = np.random.choice(p, s, replace=False)\n",
    "    beta[true_support_set] = np.random.uniform(1, 2, s)\n",
    "    # X\n",
    "    X = np.empty((n, p))\n",
    "    X[:, 0] = np.random.normal(0, 1, n)\n",
    "    for j in range(1, p):\n",
    "        X[:, j] = rho * X[:, j - 1] + np.sqrt(1-rho**2) * np.random.normal(0, 1, n)\n",
    "    # y\n",
    "    xbeta = np.clip(X @ beta, -30, 30)\n",
    "    p = 1 / (1 + np.exp(-xbeta))\n",
    "    y = np.random.binomial(1, p)\n",
    "\n",
    "    return X, y, beta, true_support_set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a42df91d",
   "metadata": {},
   "source": [
    "We then use this function to generate a data set containg 500 observations and set only 5 of the 500 variables to have effect on the expectation of the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da82b90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predictor variables of the first five samples: \n",
      " [[ 0.69737282  0.37856863  0.55593142 -0.5971624   0.39692106]\n",
      " [-1.73742924 -1.6743813   0.18271199 -0.08962145 -0.43781848]\n",
      " [ 0.1158557   0.82780721  2.0148995   1.78473305  1.770524  ]\n",
      " ...\n",
      " [-0.72372136  0.44922885  0.65933275 -0.0693512  -0.91185329]\n",
      " [ 1.7275667   1.4409185   1.22541887  0.38692584 -0.6191575 ]\n",
      " [ 0.05005725 -0.1412343   0.82986437 -2.14078613 -2.09797562]]\n",
      "The first five noisy observations: \n",
      " [0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "n, p, s, rho = 500, 500, 5, 0.5\n",
    "X, y, true_params, true_support_set = make_logistic_data(n, p, s, rho , 0)\n",
    "\n",
    "print(\"The predictor variables of the first five samples:\",'\\n',X[:,:5])\n",
    "print(\"The first five noisy observations:\", '\\n', y[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61544564",
   "metadata": {},
   "source": [
    "### Define function to calculate negative log-likelihood of logistic regression\n",
    "\n",
    "Secondly, we define the loss function `logistic_loss` accorting to [1](#loss) that matches the data generating function `make_logistic_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29c7bf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_loss(params):\n",
    "    xbeta = jnp.clip(X @ params, -30, 30)\n",
    "    return jnp.sum(jnp.log(1 + jnp.exp(xbeta)) - y * xbeta)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "415b29a7",
   "metadata": {},
   "source": [
    "### Use SIC to decide the optimal support size\n",
    "\n",
    "There are four types of information criterion can be implemented in `skscope.utilities`:\n",
    "- Akaike information criterion (AIC)\n",
    "- Bayesian information criterion (BIC)\n",
    "- Extend BIC (EBIC)\n",
    "- Special information criterion (SIC)\n",
    "  \n",
    "You can just need one line of code to call any IC, here we use SIC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3f72f8d-5989-48b9-b85f-b3f44c4bd958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skscope.utilities import SIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50bcfc21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 2.9305684566497803 seconds\n"
     ]
    }
   ],
   "source": [
    " # Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "solver_ic = ScopeSolver(p, sparsity = range(1, 6), sample_size=n, ic_method = SIC)\n",
    "params_ic = solver_ic.solve(logistic_loss, jit=True)\n",
    "\n",
    "# Calculate runtime\n",
    "runtime = time.time() - start_time\n",
    "print(\"Runtime:\", runtime, \"seconds\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5981a88e",
   "metadata": {},
   "source": [
    "Now the `solver.params` contains the coefficients of logistic model with no more than 5 variables. That is, those variables with a coefficient 0 is unused in the model:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7352ee5e",
   "metadata": {},
   "source": [
    "We can further compare the coefficients estimated by `skscope` and the real coefficients in three-fold:\n",
    "\n",
    "* The true support set and the estimated support set\n",
    "\n",
    "* The true nonzero parameters and the estimated nonzero parameters\n",
    "\n",
    "* The true loss value and the estimated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b080ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True support set:  [ 90 254 283 445 461]\n",
      "Estimated support set:  [ 90 254 283 445 461]\n"
     ]
    }
   ],
   "source": [
    "print(\"True support set: \", (true_support_set))\n",
    "print(\"Estimated support set: \", (solver_ic.support_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35c717e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True parameters:  [1.45985588 1.0446123  1.79979588 1.07695645 1.51883515]\n",
      "Estimated parameters:  [1.49872541 1.03224578 2.04393697 1.32145707 1.50325417]\n"
     ]
    }
   ],
   "source": [
    "print(\"True parameters: \", true_params[true_support_set])\n",
    "print(\"Estimated parameters: \", solver_ic.params[solver_ic.support_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ec381f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True loss value:  159.59784\n",
      "Estimated loss value:  157.65933\n"
     ]
    }
   ],
   "source": [
    "print(\"True loss value: \", logistic_loss(true_params))\n",
    "print(\"Estimated loss value: \", logistic_loss(solver_ic.params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b518e96a-760d-449b-887d-235386707798",
   "metadata": {},
   "source": [
    "### Use CV to decide the optimal support size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b65df7e8-d0bd-4e17-9935-73924c6df54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 8.449155330657959 seconds\n"
     ]
    }
   ],
   "source": [
    "def logistic_loss_cv(params, data):\n",
    "    xbeta = jnp.clip(data[0] @ params, -30, 30)\n",
    "    return jnp.sum(jnp.log(1 + jnp.exp(xbeta)) - data[1] * xbeta)\n",
    "\n",
    "# Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "solver_cv = ScopeSolver(p, sparsity = range(1, 6), sample_size = n, cv = 5,\n",
    "                        split_method=lambda data, index: (data[0][index, :], data[1][index]))\n",
    "params_cv = solver_cv.solve(logistic_loss_cv, jit=True, data=(X, y))\n",
    "\n",
    "# Calculate runtime\n",
    "runtime = time.time() - start_time\n",
    "print(\"Runtime:\", runtime, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7073834c-ac4c-4b77-982e-045c033091bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True support set:  [ 90 254 283 445 461]\n",
      "Estimated support set:  [ 90 254 283 445 461]\n"
     ]
    }
   ],
   "source": [
    "print(\"True support set: \", (true_support_set))\n",
    "print(\"Estimated support set: \", (solver_cv.support_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "649553e0-e26b-4fcd-a265-4b489f03c5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True parameters:  [1.45985588 1.0446123  1.79979588 1.07695645 1.51883515]\n",
      "Estimated parameters:  [1.49872597 1.0322461  2.04393774 1.32145742 1.50325463]\n"
     ]
    }
   ],
   "source": [
    "print(\"True parameters: \", true_params[true_support_set])\n",
    "print(\"Estimated parameters: \", solver_cv.params[solver_cv.support_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e298883-ed13-4f19-92a4-c82f1d851ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True loss value:  159.59784\n",
      "Estimated loss value:  157.65933\n"
     ]
    }
   ],
   "source": [
    "print(\"True loss value: \", logistic_loss(true_params))\n",
    "print(\"Estimated loss value: \", logistic_loss(solver_cv.params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd36568-5f5e-41cd-b9af-9bde197ae509",
   "metadata": {},
   "source": [
    "Comparing the results of SIC and CV criteria, we find that while maintaining high accuracy in variable selection, SIC exhibits a clear time advantage."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71960a6d",
   "metadata": {},
   "source": [
    "### Compare the results under two different circumstances: using warmstart and not using warmstart."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b372b20-7c2a-485e-a3a7-8eea47b46750",
   "metadata": {},
   "source": [
    "#### Using warmstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95bab082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 1.8910024166107178 seconds\n"
     ]
    }
   ],
   "source": [
    "# Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "solver_ws = ScopeSolver(p, s)\n",
    "params_ws = solver_ws.solve(logistic_loss, jit=True)\n",
    "\n",
    "# Calculate runtime\n",
    "runtime = time.time() - start_time\n",
    "print(\"Runtime:\", runtime, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b7f6b8a-7ca3-42be-a5ac-1806b3612ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True support set:  [ 90 254 283 445 461]\n",
      "Estimated support set:  [ 90 254 283 445 461]\n"
     ]
    }
   ],
   "source": [
    "print(\"True support set: \", (true_support_set))\n",
    "print(\"Estimated support set: \", (solver_ws.support_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b975ef32-a9ea-49b2-9aa0-987c6968998b",
   "metadata": {},
   "source": [
    "#### Not using warmstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d256122-a81d-4ddb-8fe9-524b00f46f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 3.612983465194702 seconds\n"
     ]
    }
   ],
   "source": [
    "# Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "solver_nws = ScopeSolver(p, s)\n",
    "solver_nws.warm_start = False\n",
    "params_nws = solver_nws.solve(logistic_loss, jit=True)\n",
    "\n",
    "# Calculate runtime\n",
    "runtime = time.time() - start_time\n",
    "print(\"Runtime:\", runtime, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9aa64ac3-6934-47a9-92b4-c7d908faece8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True support set:  [ 90 254 283 445 461]\n",
      "Estimated support set:  [ 90 254 283 445 461]\n"
     ]
    }
   ],
   "source": [
    "print(\"True support set: \", (true_support_set))\n",
    "print(\"Estimated support set: \", (solver_nws.support_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1061c7f5-48de-409a-8fd7-751b5c5922ad",
   "metadata": {},
   "source": [
    "Hint: all solvers default to using warmstart, which can slightly prolong computation time if not utilized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac9bc24-bcd1-4a8a-b451-f29bc083448f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skscope_env",
   "language": "python",
   "name": "skscope_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
