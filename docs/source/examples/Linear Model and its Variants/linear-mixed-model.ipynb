{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-dimensional linear mixed model\n",
    "Consider the linear mixed model $y=X\\beta^*+Z\\gamma+\\epsilon$ with $n$ clusters and each cluster $i$ has $m_i, i=1,\\cdots,n$ obesrvations such that\n",
    "$$\n",
    "    \\begin{bmatrix} y_1 \\\\ y_2\\\\ \\vdots \\\\ y_n \\end{bmatrix}=\n",
    "    \\begin{bmatrix} X^1 \\\\ X^2\\\\ \\vdots \\\\ X^n \\end{bmatrix}\\beta^* + \n",
    "    \\begin{bmatrix} & Z^1 & 0 &\\cdots & 0 \\\\ & 0 & Z^2 &\\cdots & 0\\\\ & \\vdots & \\vdots & & \\vdots\\\\ & 0 & 0 &\\cdots & Z^n  \\\\\\end{bmatrix}\n",
    "    \\begin{bmatrix} \\gamma_1 \\\\ \\gamma_2\\\\ \\vdots \\\\ \\gamma_n \\end{bmatrix}+\n",
    "    \\begin{bmatrix} \\epsilon_1 \\\\ \\epsilon_2\\\\ \\vdots \\\\ \\epsilon_n \\end{bmatrix}\n",
    "$$\n",
    "where $y_i\\in\\mathbb{R}^{m_i}$, $X^{i}\\in\\mathbb{R}^{m_i\\times p}$, $Z^{i}\\in\\mathbb{R}^{m_i\\times q}$  are the response vector, fixed effects design matrix, random effects design matrix of th $i$-th cluster respectively and $\\beta^*\\in\\mathbb{R}^p$ is the unknown fixed effects and $\\gamma_i\\in\\mathbb{R}^q, i=1,\\cdots,n$ are unknown random effects, $\\epsilon_i\\in\\mathbb{R}^{m_i}, i=1,\\cdots,n$ are noise vectors. In this example, we use ``scope`` to recover the saprse support of the high-dimensional fixed effects $\\beta$. Our method is based on a quasi-likelihood method proposed by [Li, Cai and Li (2022).](https://www.tandfonline.com/doi/abs/10.1080/01621459.2021.1888740?journalCode=uasa20) Specifically, for a positive constant $a>0$, we define the proxy of the covariance matrix $\\Sigma_a\\in\\mathbb{R}^{N\\times N}$ with its diagonal block being $\\Sigma_a^i:=aZ^i(Z^i)^{\\top}+I_{m_i}$ where $N=\\sum_{i=1}^n m_i$. Then, we transform original data $(X,y)$ to $(X_a, y_a):=(\\Sigma_{a}^{-1/2}X,\\Sigma_{a}^{-1/2}y)$ and fit the following sparse regression\n",
    "$$\n",
    "\\hat{\\beta}=\\arg\\min_{\\beta\\in\\mathbb{R}^p}\\frac{1}{2\\text{trace}(\\Sigma_a^{-1})}\\|y_a-X_a\\beta\\|_2^2 \\text{ s.t. } \\|\\beta\\|_0\\leq k.\n",
    "$$\n",
    "Here, we set $p=50, q=4, n=15, m_1=\\cdots=m_n=8$ and thus $N=mn=120$ and $\\|\\beta^*\\|_0=3$ with its nonzero components being $(1, 0.5, 0.3)$. Rows of design matrices $X^i$ and $Z^i$ are generated from Gaussian distribution with mean and covariance structure specificed in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scope import ScopeSolver\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (120, 50)\n",
      "Z shape:  (120, 60)\n"
     ]
    }
   ],
   "source": [
    "def make_data(m=8, n=30, p=300, q=8, sigma=0.25, rho=0.2, seed=0):\n",
    "    '''\n",
    "    m: number of observations of each cluster\n",
    "    n: number of clusters\n",
    "    p: dimension of fixed effect\n",
    "    q: dimension of random effect\n",
    "    '''\n",
    "    N = m * n\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    def func(i, j):\n",
    "        m = np.maximum(i, j)\n",
    "        return np.where(m<=q-1, rho**(abs(i-j)), 0)\n",
    "    Sigma_xz = np.fromfunction(func, (p, q))  # covariance between X and Z\n",
    "    \n",
    "    Sigma = np.block([[np.eye(p), Sigma_xz],\n",
    "                      [Sigma_xz.T, np.eye(q)]])\n",
    "    \n",
    "    X_Z = rng.multivariate_normal(np.zeros(p+q), Sigma, size=N)\n",
    "    X, Z_stack = X_Z[:, :p], X_Z[:, p:]\n",
    "    Z = np.zeros((N, n*q))\n",
    "    for i in range(n):\n",
    "        Z[(i*m):((i+1)*m), (i*q):((i+1)*q)] = Z_stack[(i*m):((i+1)*m), :]\n",
    "\n",
    "    beta = np.zeros(p)\n",
    "    beta[[1, 5, 10]] = [1, 0.5, 0.3]\n",
    "    Psi = np.fromfunction(lambda i, j: 0.56**(abs(i-j)), (q, q))  # covariance of random effect gamma\n",
    "    gamma = np.ravel(rng.multivariate_normal(np.zeros(q), Psi, size=n))  # concate n random effect gamma_i\n",
    "\n",
    "    noise = rng.normal(size=N) * 0.25\n",
    "    y = X @ beta + Z @ gamma + noise\n",
    "    return X, Z, Z_stack, y, beta, gamma\n",
    "\n",
    "\n",
    "m, n, p, q = 8, 15, 50, 4\n",
    "N = m * n\n",
    "X, Z, Z_stack, y, beta, gamma = make_data(m=m, n=n, p=p, q=q, seed=0)\n",
    "print('X shape: ', X.shape)\n",
    "print('Z shape: ', Z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lmm_scope(X, Z, y, m, a, k):\n",
    "    N, p = X.shape\n",
    "    q = Z.shape[1]\n",
    "    n = int(N / m)\n",
    "\n",
    "    Sigma_a = np.zeros((N, N))\n",
    "    for i in range(n):\n",
    "        Z_i = Z[(i*m):((i+1)*m), :]\n",
    "        Sigma_a[(i*m):((i+1)*m), (i*m):((i+1)*m)] = a * Z_i @ Z_i.T + np.eye(m)\n",
    "    w, v = np.linalg.eig(Sigma_a)\n",
    "    w, v = np.real(w), np.real(v)\n",
    "    L = v @ np.diag(w **(-0.5)) @ v.T  # normalized matrix\n",
    "    X_a, y_a = L @ X, L @ y\n",
    "\n",
    "    def custom_objective(params):\n",
    "        loss = jnp.sum((y_a - X_a @ params) ** 2) / jnp.trace(v @ np.diag(w **(-1)) @ v.T)\n",
    "        return loss\n",
    "    \n",
    "    solver = ScopeSolver(p, k)\n",
    "    params = solver.solve(custom_objective)\n",
    "    loss = np.mean((y_a - X_a @ params) ** 2)\n",
    "    return params, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation w.r.t a\n",
    "a_list = np.arange(0, 10, 1)\n",
    "loss_best = None\n",
    "beta_list, loss_list = [], []\n",
    "for a in a_list:\n",
    "    beta_a, loss_a = lmm_scope(X, Z, y, m=m, a=a, k=3)\n",
    "    if (loss_best is None) or (loss_a < loss_best):\n",
    "        a_best = a\n",
    "        beta_best = beta_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurate sparse recovery:  True\n",
      "True fixed effect:  [1.  0.5 0.3]\n",
      "Estimated fixed effect:  [1.009 0.497 0.284]\n"
     ]
    }
   ],
   "source": [
    "true_support = np.nonzero(beta)[0]\n",
    "estimated_support = np.nonzero(beta_best)[0]\n",
    "\n",
    "print('Accurate sparse recovery: ', (true_support == estimated_support).all())\n",
    "print('True fixed effect: ', beta[true_support])\n",
    "print('Estimated fixed effect: ', beta_best[estimated_support].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error of MixedLM:  0.483\n",
      "Error of scope:  0.018\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.regression.mixed_linear_model import MixedLM as mlm\n",
    "groups = []\n",
    "for i in range(n):\n",
    "    groups += [i] * m\n",
    "\n",
    "model = mlm(endog=y, exog=X, groups=groups, exog_re=Z_stack)\n",
    "result = model.fit()\n",
    "print('Error of MixedLM: ', np.linalg.norm(result.fe_params - beta).round(3))\n",
    "print('Error of scope: ', np.linalg.norm(beta_best - beta).round(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
