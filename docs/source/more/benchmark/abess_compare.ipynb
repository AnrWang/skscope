{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with `abess`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we compare the performance (recovery accuracy and computation time) of `skscope` and `abess`on three tasks as follows:\n",
    "\n",
    "- Linear Regression\n",
    "- Non-negative Linear Regression\n",
    "- Logistic Regression.\n",
    "\n",
    "Besides, we compare the corresponding performance with different data (sample size $n$, feature number $p$ and support size $s$) dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from skscope import ScopeSolver\n",
    "\n",
    "\n",
    "from abess.datasets import make_glm_data\n",
    "from abess import LinearRegression, LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the main test function which records the recovery accuracy and computation time of both methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_time(n=500, p=1000, s=5, random_state=None):\n",
    "    print('='*20 + f'  n={n}, p={p}, s={s}  ' + '='*20 )\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    true_support_set = rng.choice(np.arange(p), size=s, replace=False)\n",
    "    real_coef = np.zeros(p)\n",
    "\n",
    "    iterables = [['Linear', 'Non-Neg', 'Logistic'], ['abess', 'skscope']]\n",
    "    index = pd.MultiIndex.from_product(iterables, names=['Task', 'Model'])\n",
    "    res = pd.DataFrame(columns=['Accuracy', 'Time'], index = index)\n",
    "\n",
    "    for type in ['Linear', 'Non-Neg', 'Logistic']:\n",
    "        if type == 'Linear':\n",
    "            real_coef[true_support_set] = rng.choice(np.arange(1, 4), size=s) * rng.choice([1, -1], size=s)\n",
    "            data = make_glm_data(n=n, p=p, k=s, family='gaussian', coef_=real_coef)\n",
    "            model = LinearRegression(support_size=s)\n",
    "            def objective(params):\n",
    "                loss = jnp.mean((y - X @ params) ** 2)\n",
    "                return loss\n",
    "            solver = ScopeSolver(p, sparsity=s)\n",
    "        elif type == 'Non-Neg':\n",
    "            real_coef[true_support_set] = rng.choice(np.arange(1, 4), size=s) * rng.choice([1], size=s)\n",
    "            data = make_glm_data(n=n, p=p, k=s, family='gaussian', coef_=real_coef)\n",
    "            model = LinearRegression(support_size=s)\n",
    "            def objective(params):\n",
    "                loss = jnp.mean((y - X @ params) ** 2)\n",
    "                return loss\n",
    "            solver = ScopeSolver(p, sparsity=s)\n",
    "        elif type == 'Logistic':\n",
    "            real_coef[true_support_set] = rng.choice(np.arange(1, 4), size=s) * rng.choice([1, -1], size=s)\n",
    "            data = make_glm_data(n=n, p=p, k=s, family='binomial', coef_=real_coef)\n",
    "            model = LogisticRegression(support_size=s)\n",
    "            def objective(params):\n",
    "                xbeta = jnp.clip(X @ params, -30, 30)\n",
    "                return jnp.mean(jnp.log(1 + jnp.exp(xbeta)) - y * xbeta)\n",
    "            solver = ScopeSolver(p, sparsity=s)\n",
    "    \n",
    "        X, y = data.x, data.y\n",
    "        \n",
    "        # abess\n",
    "        t_begin = time.time()\n",
    "        model.fit(X, y)\n",
    "        t_abess = time.time() - t_begin\n",
    "        acc_abess = len(set(np.nonzero(model.coef_)[0]) & set(true_support_set)) / s\n",
    "        res.loc[(type, 'abess')] = [acc_abess, np.round(t_abess, 4)]\n",
    "        \n",
    "        # skscope\n",
    "        t_begin = time.time()\n",
    "        params = solver.solve(objective, jit=True)\n",
    "        t_skscope = time.time() - t_begin\n",
    "        acc_skscope = len(set(np.nonzero(params)[0]) & set(np.nonzero(data.coef_)[0])) / s\n",
    "        res.loc[(type, 'skscope')] = [acc_skscope, np.round(t_skscope, 4)]\n",
    "\n",
    "    print(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compare these three tasks with $$(n, p, s)\\in\\{(500, 1000, 5), (2000, 5000, 10), (5000, 10000, 10)\\}.$$\n",
    "\n",
    "Certainly, `abess` is faster than `skscope` since all three tasks are generalized linear model and are specicialized class for `abess`.\n",
    "\n",
    "This phenomenon is admmissible since the auto-differention procedure of `skscope` is general and takes more computation time.\n",
    "\n",
    "All results are shwon in the following tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================  n=500, p=1000, s=5  ====================\n",
      "                 Accuracy    Time\n",
      "Task     Model                   \n",
      "Linear   abess        1.0   0.006\n",
      "         skscope      1.0  0.2256\n",
      "Non-Neg  abess        1.0   0.011\n",
      "         skscope      1.0  0.1591\n",
      "Logistic abess        1.0  0.0168\n",
      "         skscope      1.0  0.2517\n",
      "====================  n=2000, p=5000, s=10  ====================\n",
      "                 Accuracy    Time\n",
      "Task     Model                   \n",
      "Linear   abess        1.0  0.2875\n",
      "         skscope      1.0  1.0385\n",
      "Non-Neg  abess        1.0  0.2477\n",
      "         skscope      1.0  1.2133\n",
      "Logistic abess        1.0  0.2196\n",
      "         skscope      1.0  1.3835\n",
      "====================  n=5000, p=10000, s=10  ====================\n",
      "                 Accuracy    Time\n",
      "Task     Model                   \n",
      "Linear   abess        1.0  1.3192\n",
      "         skscope      1.0  5.8157\n",
      "Non-Neg  abess        1.0  1.4239\n",
      "         skscope      1.0  5.3028\n",
      "Logistic abess        1.0  1.1628\n",
      "         skscope      1.0  5.1351\n"
     ]
    }
   ],
   "source": [
    "settings = [\n",
    "    (500, 1000, 5),\n",
    "    (2000, 5000, 10),\n",
    "    (5000, 10000, 10),\n",
    "]\n",
    "for setting in settings:\n",
    "    n, p, s = setting\n",
    "    test_time(n=n, p=p, s=s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skscope",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
